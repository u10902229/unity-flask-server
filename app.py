from flask import Flask, request, jsonify, Response
import csv
import os
import pandas as pd
import numpy as np
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials

app = Flask(__name__)
csv_file_path = "interaction_log.csv"

# ---------------- Google Sheets åˆå§‹åŒ– ----------------
def get_sheet(spreadsheet_id: str, worksheet_title: str = None):
    sa_json = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON")
    if not sa_json:
        raise RuntimeError("âŒ GOOGLE_SERVICE_ACCOUNT_JSON not set in environment variables")

    creds_dict = json.loads(sa_json)
    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    gc = gspread.authorize(creds)

    sh = gc.open_by_key(spreadsheet_id)
    if worksheet_title:
        ws = sh.worksheet(worksheet_title)
    else:
        ws = sh.sheet1
    return ws


@app.route('/')
def index():
    return 'âœ… Flask ä¼ºæœå™¨å·²é‹ä½œï¼'


# ---------------- æ¥æ”¶è³‡æ–™ ----------------
@app.route('/upload', methods=['POST'])
def upload():
    data = request.get_json()

    print("\nğŸ“¥ã€æ”¶åˆ°äº’å‹•è³‡æ–™ã€‘")
    for key, value in data.items():
        print(f"{key:<18}: {value}")
    print("ğŸ“ å·²è¨˜éŒ„\n")

    def get(key):
        value = data.get(key, "")
        if value == 0 or value == 0.0:
            return "0"
        return str(value) if value != "" else ""

    row = [
        get("user_id"),
        get("device_type"),
        get("task_type"), get("interaction_type"), get("trial_no"),
        get("target_index"), get("grid_index"),
        get("reaction_time"), get("level_name"),
        get("start_time"), get("end_time"),
        get("gaze_target_x"), get("gaze_target_y"), get("gaze_target_z"),
        get("gaze_x"), get("gaze_y"), get("gaze_z"),
        get("interaction_result"),
        get("process"), get("appear_time"), get("timestamp")
    ]

    print("ğŸ“¤ æº–å‚™å¯«å…¥ Google Sheets:", row)

    with open(csv_file_path, mode='a', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(row)

    try:
        SHEET_ID = "1C9CJMjEiXeqQYdYVojtpX0yVQdn6W4H4KuQ7PlsiGGU"
        ws = get_sheet(SHEET_ID, "å·¥ä½œè¡¨1")
        ws.append_row(row, value_input_option="USER_ENTERED")
        print("âœ… å·²åŒæ­¥åˆ° Google Sheets")
    except Exception as e:
        import traceback
        print("âš ï¸ Google Sheets åŒæ­¥å¤±æ•—:", e)
        traceback.print_exc()

    return jsonify({"message": "âœ… è³‡æ–™å¯«å…¥æˆåŠŸ"})


# ---------------- èšåˆåˆ†æ ----------------
@app.route('/aggregate', methods=['GET'])
def aggregate():
    try:
        SHEET_ID = "1C9CJMjEiXeqQYdYVojtpX0yVQdn6W4H4KuQ7PlsiGGU"
        ws = get_sheet(SHEET_ID, "å·¥ä½œè¡¨1")

        rows = ws.get_all_values()
        if len(rows) <= 1:
            return jsonify({"message": "Google Sheet is empty"}), 200

        df = pd.DataFrame(rows[1:], columns=rows[0])
        if df.empty:
            return jsonify({"message": "Google Sheet empty"}), 200

        df["reaction_time"] = pd.to_numeric(df["reaction_time"], errors="coerce")
        if "interaction_result" in df.columns:
            df["interaction_result"] = pd.to_numeric(df["interaction_result"], errors="coerce")

        results = {}

        # ---------- 1. çœ¼å‹• ----------
        eye_data = df[df["level_name"].str.strip().str.lower() == "practicegaze"].copy()
        if not eye_data.empty:
            cols = ["gaze_target_x", "gaze_target_y", "gaze_target_z",
                    "gaze_x", "gaze_y", "gaze_z"]
            for c in cols:
                eye_data[c] = pd.to_numeric(eye_data[c], errors="coerce")
            eye_data = eye_data.dropna(subset=cols)
            if not eye_data.empty:
                eye_data["error"] = np.sqrt(
                    (eye_data["gaze_target_x"] - eye_data["gaze_x"])**2 +
                    (eye_data["gaze_target_y"] - eye_data["gaze_y"])**2 +
                    (eye_data["gaze_target_z"] - eye_data["gaze_z"])**2
                )
                device_eye = eye_data.groupby("device_type")["error"].mean().reset_index()
                results["eye_accuracy"] = {
                    "per_device": device_eye.to_dict(orient="records"),
                    "overall_avg": round(device_eye["error"].mean(), 6)
                }

        # ---------- 2. èªéŸ³ ----------
        voice_data = df[df["level_name"] == "practicevoice"].copy()
        if not voice_data.empty:
            device_voice = voice_data.groupby("device_type")["interaction_result"].mean().reset_index()
            device_voice.rename(columns={"interaction_result": "accuracy"}, inplace=True)
            results["voice_accuracy"] = {
                "per_device": device_voice.to_dict(orient="records"),
                "overall_avg": round(device_voice["accuracy"].mean(), 6)
            }

        # ---------- 3. é»æ“Š ----------
        point_data = df[df["level_name"] == "practicepoint"].copy()
        if not point_data.empty:
            device_point = point_data.groupby("device_type")["interaction_result"].mean().reset_index()
            device_point.rename(columns={"interaction_result": "accuracy"}, inplace=True)
            results["hand_point_accuracy"] = {
                "per_device": device_point.to_dict(orient="records"),
                "overall_avg": round(device_point["accuracy"].mean(), 6)
            }

        # ---------- 4. æ‹–ç§» ----------
        grab_data = df[df["level_name"] == "practicegrab"].copy()
        if not grab_data.empty:
            device_grab = grab_data.groupby("device_type")["interaction_result"].mean().reset_index()
            device_grab.rename(columns={"interaction_result": "accuracy"}, inplace=True)
            results["hand_drag_accuracy"] = {
                "per_device": device_grab.to_dict(orient="records"),
                "overall_avg": round(device_grab["accuracy"].mean(), 6)
            }

        # ---------- 5. å„ªæƒ åˆ¸ä¹å®®æ ¼ ----------
        coupon_data = df[df["level_name"].str.lower() == "coupongame"].copy()
        if not coupon_data.empty:
            grid_map = {
                "1": "1å·¦ä¸Š", "2": "2ä¸­ä¸Š", "3": "3å³ä¸Š",
                "4": "4å·¦ä¸­", "5": "5ä¸­å¿ƒ", "6": "6å³ä¸­",
                "7": "7å·¦ä¸‹", "8": "8ä¸­ä¸‹", "9": "9å³ä¸‹"
            }
            coupon_data["grid_label"] = coupon_data["grid_index"].map(grid_map)
            device_coupon = coupon_data.groupby(
                ["device_type", "grid_index", "grid_label"]
            )["reaction_time"].mean().reset_index()
            coupon_overall = coupon_data.groupby(
                ["grid_index", "grid_label"]
            )["reaction_time"].mean().reset_index()
            results["coupon_reaction_time"] = {
                "per_device": device_coupon.to_dict(orient="records"),
                "overall_avg": coupon_overall.to_dict(orient="records")
            }

        # ---------- 6. å”ä½œå»¶é² ----------
        collab_levels = ["eye", "voice", "point", "grab",
                         "eye+voice", "hand+voice", "hand+eye", "hand+eye+voice"]
        collab_data = df[df["level_name"].isin(collab_levels)].copy()

        if collab_data.empty:
            results["collaboration_latency"] = {"message": "No collaboration data found"}
        else:
            collab_data["reaction_time"] = pd.to_numeric(collab_data["reaction_time"], errors="coerce")
            collab_data = collab_data.dropna(subset=["reaction_time"])

            if collab_data.empty:
                results["collaboration_latency"] = {"message": "No valid reaction_time data"}
            else:
                name_map = {
                    "eye": "çœ¼å‹•äº’å‹•",
                    "voice": "èªéŸ³äº’å‹•",
                    "point": "æ‰‹å‹¢é»æ“Š",
                    "grab": "æ‰‹å‹¢æ‹–ç§»",
                    "eye+voice": "çœ¼å‹•+èªéŸ³",
                    "hand+voice": "æ‰‹å‹¢+èªéŸ³",
                    "hand+eye": "æ‰‹å‹¢+çœ¼å‹•",
                    "hand+eye+voice": "æ‰‹å‹¢+çœ¼å‹•+èªéŸ³"
                }
                collab_data["level_label"] = collab_data["level_name"].map(name_map)

                # --- æ¯è£ç½® + é—œå¡ å¹³å‡ä¸€æ¬¡ ---
                per_level_avg = collab_data.groupby(
                    ["device_type", "level_name", "level_label"]
                )["reaction_time"].mean().reset_index()

                # --- å–®ä¸€äº’å‹•å¹³å‡ï¼ˆæ¬Šé‡ä¸€è‡´ï¼‰---
                single_levels = ["eye", "voice", "point", "grab"]
                device_single = per_level_avg[per_level_avg["level_name"].isin(single_levels)] \
                    .groupby("device_type")["reaction_time"].mean().reset_index() \
                    .rename(columns={"reaction_time": "single_interaction_avg"})

                # --- å¤šäº’å‹•å¹³å‡ï¼ˆæ¬Šé‡ä¸€è‡´ï¼‰---
                multi_levels = ["eye+voice", "hand+voice", "hand+eye", "hand+eye+voice"]
                device_multi = per_level_avg[per_level_avg["level_name"].isin(multi_levels)] \
                    .groupby("device_type")["reaction_time"].mean().reset_index() \
                    .rename(columns={"reaction_time": "multi_interaction_avg"})

                device_summary = pd.merge(device_single, device_multi, on="device_type", how="outer")

                # --- å„é—œå¡æ•´é«”å¹³å‡ ---
                collab_overall = per_level_avg.groupby(["level_name", "level_label"])["reaction_time"].mean().reset_index()

                results["collaboration_latency"] = {
                    "per_device": per_level_avg.to_dict(orient="records"),
                    "overall_avg": collab_overall.to_dict(orient="records"),
                    "per_device_summary": device_summary.to_dict(orient="records")
                }

        # âš ï¸ çµ±ä¸€è½‰ç‚º JSONï¼Œæ’é™¤ NaN
        safe_json = json.dumps(results, ensure_ascii=False, indent=2, default=str)
        safe_json = safe_json.replace("NaN", "null")
        return Response(safe_json, mimetype='application/json')

    except Exception as e:
        import traceback
        print("âŒ /aggregate ç™¼ç”ŸéŒ¯èª¤:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500
